{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16757bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from win32com.client import Dispatch\n",
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7056d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def wait_path_exists(path, sleep_time=0.25, peridos_to_wait=40):\n",
    "    time_counter = 0\n",
    "    while (not os.path.exists(path)) or os.path.exists(f'C:/Users/user/Taikyu_project/stuff/Super Fish/Realtime/gamemaker_flg.txt'):\n",
    "        time.sleep(sleep_time)\n",
    "        time_counter += 1\n",
    "        if time_counter > peridos_to_wait:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2c2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "\n",
    "def find_file(file_name):\n",
    "    cur_dir = os.getcwd()\n",
    "\n",
    "    for root, dirs, files in os.walk(cur_dir):\n",
    "        if file_name in files:\n",
    "            return os.path.join(root, file_name)\n",
    "\n",
    "    raise FileNotFoundError(f\"File '{file}' not found in subdirectories of {cur_dir}\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    if not config_path.endswith(\".yml\"):\n",
    "        config_path += \".yml\"\n",
    "    config_path = find_file(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    return AttrDict(config)\n",
    "\n",
    "\n",
    "\n",
    "config_file='config.yml'\n",
    "\n",
    "config = load_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c00672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_iwanna(folder, exe):\n",
    "    os.chdir(folder)\n",
    "    return subprocess.Popen([exe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f1cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_iwanna(process):\n",
    "    os.kill(process.pid, signal.SIGTERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873bf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions_to_controls(walk_length, jump_height):\n",
    "    \n",
    "    controls_array = np.zeros([6,4], dtype=np.int8)\n",
    "    \n",
    "    jump_true = 0\n",
    "    \n",
    "    for i in range(6):\n",
    "        \n",
    "        if walk_length > 0:\n",
    "            \n",
    "            controls_left = 0\n",
    "            controls_right = 1\n",
    "                \n",
    "            walk_length -= 1\n",
    "        \n",
    "        elif walk_length < 0:\n",
    "            \n",
    "            controls_left = 1\n",
    "            controls_right = 0\n",
    "            \n",
    "            walk_length += 1\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            controls_left = 0\n",
    "            controls_right = 0\n",
    "            \n",
    "        if jump_height > 0 and jump_true == 0:\n",
    "            \n",
    "            controls_jump = 1\n",
    "            \n",
    "            jump_true = 1\n",
    "            jump_height -= 1\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            controls_jump = 0\n",
    "            \n",
    "            jump_height -= 1\n",
    "            \n",
    "        if jump_height <= 0 and jump_true == 1:\n",
    "            \n",
    "            controls_jump_release = 1\n",
    "            \n",
    "            jump_true = 0\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            controls_jump_release = 0\n",
    "            \n",
    "        controls_array[i] = [controls_left,controls_right,controls_jump,controls_jump_release]\n",
    "    \n",
    "    return controls_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de3b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_controls_txt(controls, file_path, rewrite=True):\n",
    "    \n",
    "    if rewrite:\n",
    "        open(file_path, 'w').close()\n",
    "    \n",
    "    for control in controls:\n",
    "        with open(file_path, 'a') as f:\n",
    "            f.write(''.join(str(x) for x in control) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed49858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_start_conditions(file_path):\n",
    "    with open(file_path) as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "    seed = int(lines[0])\n",
    "    timeline_start = int(lines[1])\n",
    "    player_x_start = float(lines[2])\n",
    "    player_y_start = float(lines[3])\n",
    "    return seed, timeline_start, player_x_start, player_y_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3130d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_start_conditions(file_path, seed, timeline_start, player_x_start, player_y_start, rewrite=True):\n",
    "    \n",
    "    if rewrite:\n",
    "        open(file_path, 'w').close()\n",
    "        \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(f'{seed}\\n')\n",
    "        file.write(f'{timeline_start}\\n')\n",
    "        file.write(f'{player_x_start}\\n')\n",
    "        file.write(f'{player_y_start}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74ba62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186, 0, 403.0, 567.4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_start_conditions(r'D:\\fangames\\I wanna be the Palladium ver1.0\\Sadistic_Music_Factory\\Realtime\\start_conditions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2f43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_controls_txt(controls, r'D:\\fangames\\I wanna be the Palladium ver1.0\\Sadistic_Music_Factory\\Realtime\\controls\\controls_test_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e533ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taikyu_screenshots.dataset import load_image_obs, zero_screenshot_load, zero_screenshot_part_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef4e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonFlg():\n",
    "    \n",
    "    def __init__(self, flg_path):\n",
    "        \n",
    "        self.raised = 0\n",
    "        self.flg_path = flg_path\n",
    "        if os.path.exists(self.flg_path):\n",
    "            os.remove(self.flg_path)\n",
    "\n",
    "        \n",
    "    def raise_flg(self):\n",
    "        \n",
    "        if self.raised == 0:\n",
    "            self.raised = 1\n",
    "            self.flg_file = open(self.flg_path, \"w\")\n",
    "            \n",
    "    def lower_flg(self):\n",
    "        \n",
    "        if self.raised == 1:\n",
    "            \n",
    "            self.flg_file.close()\n",
    "            os.remove(self.flg_path)\n",
    "            self.raised = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec67212",
   "metadata": {},
   "outputs": [],
   "source": [
    "flg = PythonFlg(r'D:\\fangames\\I wanna be the Palladium ver1.0\\Sadistic_Music_Factory\\Realtime\\controls\\python_flg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93833d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flg.raise_flg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acc6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flg.lower_flg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da954421",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_controls_txt(actions_to_controls(0,5), r'D:\\fangames\\I wanna be the Palladium ver1.0\\Sadistic_Music_Factory\\Realtime\\controls\\controls_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8717a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IwannaEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, root_folder, exe_folder, exe, config, seed=None, timeline_start=None, player_x_start=None, player_y_start=None):\n",
    "        \n",
    "        \n",
    "        self.config = config\n",
    "        self.flg = PythonFlg(root_folder + 'Realtime/python_flg.txt')\n",
    "        \n",
    "        super(IwannaEnv, self).__init__()\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=0, high=1,\n",
    "                                            shape=(4, self.config.environment.image_size, self.config.environment.image_size), \n",
    "                                            dtype=np.float32)\n",
    "        \n",
    "        self.action_space = spaces.Box(low=np.array([-6, 6]), high=np.array([0, 6]), dtype=np.float32)\n",
    "        \n",
    "        self.exe_folder = exe_folder\n",
    "        self.exe = exe\n",
    "        self.root_folder = root_folder\n",
    "        self.screenshot_folder = root_folder + 'Realtime/screenshots/'\n",
    "        self.screenshot_add_folder = root_folder + 'Realtime/screenshots_add/'\n",
    "        self.controls_folder = root_folder + 'Realtime/controls/'\n",
    "        \n",
    "        self.zero_screenshot = zero_screenshot_load(root_folder + 'Realtime/Zero_screenshot.png',\n",
    "                                                    image_size=self.config.environment.image_size,\n",
    "                                                    pad=self.config.parameters.edges_dataset.pad, \n",
    "                                                    aperture_size=self.config.parameters.edges_dataset.aperture_size)\n",
    "        self.zero_screenshot_part = zero_screenshot_part_load(root_folder + 'Realtime/Zero_screenshot_part.png', \n",
    "                                                    image_size=self.config.environment.image_size, \n",
    "                                                    part_size=self.config.parameters.edges_dataset.part_size, \n",
    "                                                    player_x=self.config.parameters.edges_dataset.zero_screenshot_player_x, \n",
    "                                                    player_y=self.config.parameters.edges_dataset.zero_screenshot_player_y, \n",
    "                                                    pad=self.config.parameters.edges_dataset.pad, \n",
    "                                                    aperture_size=self.config.parameters.edges_dataset.aperture_size)\n",
    "        \n",
    "        if seed is None or timeline_start is None or player_x_start is None or player_y_start is None:\n",
    "            self.seed, self.timeline_start, self.player_x_start, self.player_y_start = read_start_conditions(root_folder + r'Realtime\\start_conditions.txt')\n",
    "        else:\n",
    "            self.set_start_conditions(seed, timeline_start, player_x_start, player_y_start)\n",
    "        \n",
    "        self.timeline_start_str = (4 - len(str(self.timeline_start))) * '0' + str(self.timeline_start)\n",
    "\n",
    "        self.timestep = 6\n",
    "        \n",
    "        self.process = None\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.flg.raise_flg()\n",
    "        \n",
    "        if self.process is not None:\n",
    "            close_iwanna(self.process)\n",
    "        \n",
    "        self.timestep = 6\n",
    "        \n",
    "        self.episode_screenshots_folder = self.screenshot_folder + f'screenshots{self.timeline_start_str}_{self.seed}/'\n",
    "        \n",
    "        self.episode_screenshots_add_folder = self.screenshot_add_folder + f'screenshots{self.timeline_start_str}_{self.seed}/'\n",
    "        \n",
    "        print(self.episode_screenshots_folder)\n",
    "        \n",
    "        self.episode_controls_folder = self.controls_folder + f'controls{self.timeline_start_str}_{self.seed}/'\n",
    "        \n",
    "        # Создаем новую папку для скриншотов\n",
    "        if os.path.exists(self.episode_screenshots_folder):\n",
    "            shutil.rmtree(self.episode_screenshots_folder)\n",
    "        os.mkdir(self.episode_screenshots_folder)\n",
    "        \n",
    "        # Создаем новую папку для доп скриншотов\n",
    "        if os.path.exists(self.episode_screenshots_add_folder):\n",
    "            shutil.rmtree(self.episode_screenshots_add_folder)\n",
    "        os.mkdir(self.episode_screenshots_add_folder)\n",
    "        \n",
    "        # Создаем новую папку для записи инпутов\n",
    "        if os.path.exists(self.episode_controls_folder):\n",
    "            shutil.rmtree(self.episode_controls_folder)\n",
    "        os.mkdir(self.episode_controls_folder)\n",
    "        \n",
    "        write_controls_txt(actions_to_controls(0,0), self.episode_controls_folder + f'controls{0}.txt')\n",
    "        \n",
    "        img_path = self.episode_screenshots_folder + f'{self.timestep}.png'\n",
    "        add_img_path = self.episode_screenshots_add_folder + f'{self.timestep}.png'\n",
    "        \n",
    "        self.flg.lower_flg()\n",
    "        \n",
    "        self.process = start_iwanna(self.exe_folder, self.exe)\n",
    "    \n",
    "        wait_path_exists(img_path)\n",
    "        wait_path_exists(add_img_path)\n",
    "        \n",
    "        observation_img, _, _, _ = load_image_obs(img_path, self.zero_screenshot, self.zero_screenshot_part, self.config)\n",
    "        \n",
    "        return observation_img\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        print(action)\n",
    "        \n",
    "        self.flg.raise_flg()\n",
    "        \n",
    "        write_controls_txt(actions_to_controls(*action), self.episode_controls_folder + f'controls{self.timestep}.txt')\n",
    "        \n",
    "        self.flg.lower_flg()\n",
    "        \n",
    "        img_path = self.episode_screenshots_folder + f'{self.timestep}.png'\n",
    "        add_info_path = self.episode_screenshots_add_folder + f'{self.timestep}.txt'\n",
    "        \n",
    "        wait_path_exists(img_path)\n",
    "        wait_path_exists(add_info_path)\n",
    "        \n",
    "        observation_img, _, reward, terminal = load_image_obs(img_path, self.zero_screenshot, self.zero_screenshot_part, self.config)\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        self.timestep += 6\n",
    "        \n",
    "        return observation_img, reward, terminal, info\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        \n",
    "        try:\n",
    "            close_iwanna(self.process)\n",
    "        except PermissionError:\n",
    "            print('Отказано в доступе при попытке остановки процесса')\n",
    "        except OSError:\n",
    "            print('Процесс не существует')\n",
    "        \n",
    "        self.flg.lower_flg()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \n",
    "        self.flg.lower_flg()\n",
    "    \n",
    "    def set_start_conditions(self, seed, timeline_start, player_x_start, player_y_start):\n",
    "        \n",
    "        write_start_conditions(root_folder + 'Realtime/start_conditions.txt', seed, timeline_start, player_x_start, player_y_start)\n",
    "        self.seed = seed\n",
    "        self.timeline_start = timeline_start\n",
    "        self.player_x_start = player_x_start\n",
    "        self.player_y_start = player_y_start\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf3b6d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You should use NatureCNN only with images not with Box([[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]], [[[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]\n\n [[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]\n\n [[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]], (3, 64, 64), float32)\n(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\nIf you are using a custom environment,\nplease check it using our env checker:\nhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m action_noise \u001b[38;5;241m=\u001b[39m NormalActionNoise(mean\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(n_actions), sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_actions))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Instantiate the agent\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTD3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCnnPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miwanna_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the agent and display a progress bar\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:132\u001b[0m, in \u001b[0;36mTD3.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_delay, target_policy_noise, target_noise_clip, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policy_noise \u001b[38;5;241m=\u001b[39m target_policy_noise\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:135\u001b[0m, in \u001b[0;36mTD3._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Running mean and running var\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:219\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    217\u001b[0m     )\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule,\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs,  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    224\u001b[0m )\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\policies.py:286\u001b[0m, in \u001b[0;36mCnnPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs, n_critics, share_features_extractor)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    273\u001b[0m     observation_space: gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mSpace,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     share_features_extractor: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    285\u001b[0m ):\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_critics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\policies.py:166\u001b[0m, in \u001b[0;36mTD3Policy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs, n_critics, share_features_extractor)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor \u001b[38;5;241m=\u001b[39m share_features_extractor\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\policies.py:171\u001b[0m, in \u001b[0;36mTD3Policy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr_schedule: Schedule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# Create actor and target\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# the features extractor should not be shared\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_actor(features_extractor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Initialize the target to have the same weights as the actor\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\policies.py:217\u001b[0m, in \u001b[0;36mTD3Policy.make_actor\u001b[1;34m(self, features_extractor)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features_extractor: Optional[BaseFeaturesExtractor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Actor:\n\u001b[1;32m--> 217\u001b[0m     actor_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Actor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mactor_kwargs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:110\u001b[0m, in \u001b[0;36mBaseModel._update_features_extractor\u001b[1;34m(self, net_kwargs, features_extractor)\u001b[0m\n\u001b[0;32m    107\u001b[0m net_kwargs \u001b[38;5;241m=\u001b[39m net_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# The features extractor is not shared, create a new one\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     features_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m net_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(features_extractor\u001b[38;5;241m=\u001b[39mfeatures_extractor, features_dim\u001b[38;5;241m=\u001b[39mfeatures_extractor\u001b[38;5;241m.\u001b[39mfeatures_dim))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:116\u001b[0m, in \u001b[0;36mBaseModel.make_features_extractor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseFeaturesExtractor:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:67\u001b[0m, in \u001b[0;36mNatureCNN.__init__\u001b[1;34m(self, observation_space, features_dim)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(observation_space, features_dim)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# We assume CxHxW images (channels first)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Re-ordering will be done by pre-preprocessing or wrapper\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_image_space(observation_space, check_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), (\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should use NatureCNN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly with images not with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are using a custom environment,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease check it using our env checker:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     75\u001b[0m n_input_channels \u001b[38;5;241m=\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     77\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(n_input_channels, \u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     78\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     84\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: You should use NatureCNN only with images not with Box([[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]], [[[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]\n\n [[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]\n\n [[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]]], (3, 64, 64), float32)\n(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\nIf you are using a custom environment,\nplease check it using our env checker:\nhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "# Create environment\n",
    "iwanna_env = IwannaEnv(root_folder='D:/fangames/I wanna be the Palladium ver1.0/Sadistic_Music_Factory/',\n",
    "               exe_folder='D:/fangames/I wanna be the Palladium ver1.0/',\n",
    "               exe='test.exe',\n",
    "               config=config)\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = iwanna_env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# Instantiate the agent\n",
    "model = TD3(\"CnnPolicy\", iwanna_env, action_noise=action_noise, buffer_size=10000, verbose=1)\n",
    "# Train the agent and display a progress bar\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"td3_iwanna_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "812ba0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwanna_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2d447f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwanna_env.flg.lower_flg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c04779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e00d513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/fangames/I wanna be the Palladium ver1.0/Sadistic_Music_Factory/Realtime/screenshots/screenshots0000_3186/\n"
     ]
    }
   ],
   "source": [
    "iwanna_env = IwannaEnv(root_folder='D:/fangames/I wanna be the Palladium ver1.0/Sadistic_Music_Factory/',\n",
    "               exe_folder='D:/fangames/I wanna be the Palladium ver1.0/',\n",
    "               exe='test.exe',\n",
    "               config=config)\n",
    "obs[0] = iwanna_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1df999dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[1] = iwanna_env.step((1,3))\n",
    "obs[2] = iwanna_env.step((-4,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a96d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_img, action, reward, terminal = obs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b6d7345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39e67f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwanna_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "class IwannaEnv(gym.Env):\n",
    "    r\"\"\"The main OpenAI Gym class.\n",
    "    It encapsulates an environment with arbitrary behind-the-scenes dynamics.\n",
    "    An environment can be partially or fully observed.\n",
    "    The main API methods that users of this class need to know are:\n",
    "    - :meth:`step` - Takes a step in the environment using an action returning the next observation, reward,\n",
    "      if the environment terminated and observation information.\n",
    "    - :meth:`reset` - Resets the environment to an initial state, returning the initial observation and observation information.\n",
    "    - :meth:`render` - Renders the environment observation with modes depending on the output\n",
    "    - :meth:`close` - Closes the environment, important for rendering where pygame is imported\n",
    "    And set the following attributes:\n",
    "    - :attr:`action_space` - The Space object corresponding to valid actions\n",
    "    - :attr:`observation_space` - The Space object corresponding to valid observations\n",
    "    - :attr:`reward_range` - A tuple corresponding to the minimum and maximum possible rewards\n",
    "    - :attr:`spec` - An environment spec that contains the information used to initialise the environment from `gym.make`\n",
    "    - :attr:`metadata` - The metadata of the environment, i.e. render modes\n",
    "    - :attr:`np_random` - The random number generator for the environment\n",
    "    Note: a default reward range set to :math:`(-\\infty,+\\infty)` already exists. Set it if you want a narrower range.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set this in SOME subclasses\n",
    "    metadata: Dict[str, Any] = {\"render_modes\": []}\n",
    "    # define render_mode if your environment supports rendering\n",
    "    render_mode: Optional[str] = None\n",
    "    reward_range = (-float(\"inf\"), float(\"inf\"))\n",
    "    spec: \"EnvSpec\" = None\n",
    "\n",
    "    # Set these in ALL subclasses\n",
    "    action_space: spaces.Space[ActType]\n",
    "    observation_space: spaces.Space[ObsType]\n",
    "\n",
    "    # Created\n",
    "    _np_random: Optional[np.random.Generator] = None\n",
    "\n",
    "    @property\n",
    "    def np_random(self) -> np.random.Generator:\n",
    "        \"\"\"Returns the environment's internal :attr:`_np_random` that if not set will initialise with a random seed.\"\"\"\n",
    "        if self._np_random is None:\n",
    "            self._np_random, seed = seeding.np_random()\n",
    "        return self._np_random\n",
    "\n",
    "    @np_random.setter\n",
    "    def np_random(self, value: np.random.Generator):\n",
    "        self._np_random = value\n",
    "\n",
    "    def step(self, action: ActType) -> Tuple[ObsType, float, bool, bool, dict]:\n",
    "        \"\"\"Run one timestep of the environment's dynamics.\n",
    "        When end of episode is reached, you are responsible for calling :meth:`reset` to reset this environment's state.\n",
    "        Accepts an action and returns either a tuple `(observation, reward, terminated, truncated, info)`.\n",
    "        Args:\n",
    "            action (ActType): an action provided by the agent\n",
    "        Returns:\n",
    "            observation (object): this will be an element of the environment's :attr:`observation_space`.\n",
    "                This may, for instance, be a numpy array containing the positions and velocities of certain objects.\n",
    "            reward (float): The amount of reward returned as a result of taking the action.\n",
    "            terminated (bool): whether a `terminal state` (as defined under the MDP of the task) is reached.\n",
    "                In this case further step() calls could return undefined results.\n",
    "            truncated (bool): whether a truncation condition outside the scope of the MDP is satisfied.\n",
    "                Typically a timelimit, but could also be used to indicate agent physically going out of bounds.\n",
    "                Can be used to end the episode prematurely before a `terminal state` is reached.\n",
    "            info (dictionary): `info` contains auxiliary diagnostic information (helpful for debugging, learning, and logging).\n",
    "                This might, for instance, contain: metrics that describe the agent's performance state, variables that are\n",
    "                hidden from observations, or individual reward terms that are combined to produce the total reward.\n",
    "                It also can contain information that distinguishes truncation and termination, however this is deprecated in favour\n",
    "                of returning two booleans, and will be removed in a future version.\n",
    "            (deprecated)\n",
    "            done (bool): A boolean value for if the episode has ended, in which case further :meth:`step` calls will return undefined results.\n",
    "                A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n",
    "                a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ) -> Tuple[ObsType, dict]:\n",
    "        \"\"\"Resets the environment to an initial state and returns the initial observation.\n",
    "        This method can reset the environment's random number generator(s) if ``seed`` is an integer or\n",
    "        if the environment has not yet initialized a random number generator.\n",
    "        If the environment already has a random number generator and :meth:`reset` is called with ``seed=None``,\n",
    "        the RNG should not be reset. Moreover, :meth:`reset` should (in the typical use case) be called with an\n",
    "        integer seed right after initialization and then never again.\n",
    "        Args:\n",
    "            seed (optional int): The seed that is used to initialize the environment's PRNG.\n",
    "                If the environment does not already have a PRNG and ``seed=None`` (the default option) is passed,\n",
    "                a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).\n",
    "                However, if the environment already has a PRNG and ``seed=None`` is passed, the PRNG will *not* be reset.\n",
    "                If you pass an integer, the PRNG will be reset even if it already exists.\n",
    "                Usually, you want to pass an integer *right after the environment has been initialized and then never again*.\n",
    "                Please refer to the minimal example above to see this paradigm in action.\n",
    "            options (optional dict): Additional information to specify how the environment is reset (optional,\n",
    "                depending on the specific environment)\n",
    "        Returns:\n",
    "            observation (object): Observation of the initial state. This will be an element of :attr:`observation_space`\n",
    "                (typically a numpy array) and is analogous to the observation returned by :meth:`step`.\n",
    "            info (dictionary):  This dictionary contains auxiliary information complementing ``observation``. It should be analogous to\n",
    "                the ``info`` returned by :meth:`step`.\n",
    "        \"\"\"\n",
    "        # Initialize the RNG if the seed is manually passed\n",
    "        if seed is not None:\n",
    "            self._np_random, seed = seeding.np_random(seed)\n",
    "\n",
    "    def render(self) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n",
    "        \"\"\"Compute the render frames as specified by render_mode attribute during initialization of the environment.\n",
    "        The set of supported modes varies per environment. (And some\n",
    "        third-party environments may not support rendering at all.)\n",
    "        By convention, if render_mode is:\n",
    "        - None (default): no render is computed.\n",
    "        - human: render return None.\n",
    "          The environment is continuously rendered in the current display or terminal. Usually for human consumption.\n",
    "        - rgb_array: return a single frame representing the current state of the environment.\n",
    "          A frame is a numpy.ndarray with shape (x, y, 3) representing RGB values for an x-by-y pixel image.\n",
    "        - rgb_array_list: return a list of frames representing the states of the environment since the last reset.\n",
    "          Each frame is a numpy.ndarray with shape (x, y, 3), as with `rgb_array`.\n",
    "        - ansi: Return a strings (str) or StringIO.StringIO containing a\n",
    "          terminal-style text representation for each time step.\n",
    "          The text can include newlines and ANSI escape sequences (e.g. for colors).\n",
    "        Note:\n",
    "            Make sure that your class's metadata 'render_modes' key includes\n",
    "            the list of supported modes. It's recommended to call super()\n",
    "            in implementations to use the functionality of this method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Override close in your subclass to perform any necessary cleanup.\n",
    "        Environments will automatically :meth:`close()` themselves when\n",
    "        garbage collected or when the program exits.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
